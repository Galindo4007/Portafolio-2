# -*- coding: utf-8 -*-
"""Portafolio2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bclB5URnI3QsnlcrhEmmtvKfqrUu2eFo
"""

# importación de las librerías
import pandas as pd # Libreria para leer archivos
import matplotlib.pyplot as plt# Libreria para graficar
from sklearn import tree # Libreria para crear el modelo de árbol de desición
from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score # Métricas de evaluación del modelo
from sklearn.model_selection import train_test_split # Divissión del modelo para los datos de entrenamiento y prueba
from sklearn.preprocessing import OneHotEncoder # Codificador para todos los datos strings que hay para la relación del modelo
from sklearn.model_selection import GridSearchCV # GridSearch para buscar los mejores Hiper parámetros
# Fin de la importación de las librerias

# Lectura del archivo de las olimpiadas
df_olympics = pd.read_csv("olympics_dataset.csv")
# Asignación de las columnas de las olimpiadas
df_olympics.columns = ["player_id","Name","Sex","Team","NOC",
                       "Year","Season","City","Sport","Event","Medal"]
# Se asignan los features y instances
X_df_olympics = df_olympics[["Sex", "Team", "NOC", "Year", "Season", "City", "Sport", "Event"]]
# Se asigna el Label
Y_df_olympics = df_olympics["Medal"]
# Se muestran los primeros datos
print(X_df_olympics.head())
print(Y_df_olympics.head())

#------------------------------ Árbol de desiciones sin Hiper parámetros ----------------------------------------------------------
# Se dividen la base de datos en los datos de prueba y de entrenamiento
X_train, X_test, y_train, y_test = train_test_split(X_df_olympics, Y_df_olympics, test_size=0.2, random_state=42)

# Se codifican los datos ya que en la mayoría de los instances son Strings y se necesitan enteros para las relaciones
encoder = OneHotEncoder(handle_unknown='ignore')

# Se codifica tanto las X de entrenamiento como las de prueba para que sigan el mismo código
X_train_encoded = encoder.fit_transform(X_train)
X_test_encoded = encoder.transform(X_test)

# Ahora si con las variables ya codificadas se crea el modelo y se ajsuta a los datos de entrenamiento para
# crear el árbol de desiciones
model_tree = tree.DecisionTreeClassifier()
model_tree.fit(X_train_encoded, y_train)

# Luego de hacen predicciones para luego comparar los resultados
y_pred = model_tree.predict(X_test_encoded)

# Se calculan las métricas correspondientes para ver los resultados del primer modelo sin ajustar ningun hiper parámetro
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')

# Información sobre el árbol de decisiones
print('Información del Árbol de desiciones sin Hiper parámetros')
print('Profundidad del árbol:', model_tree.get_depth())
print('Número de hojas:', model_tree.get_n_leaves())
print('Número de nodos:', model_tree.tree_.node_count)
print()

# Puntaje del Arbol de desiciones después de las pruebas
print("Resultados del Árbol de desiciones sin Hiper parámetros")
print('Score de accuracy:', round(accuracy, 4))
print('Score de precisión:', round(precision, 4))
print('Score f1:', round(f1, 4))
print('Score de recall:', round(recall, 4))

# Se crea una paradigam de hiperparametros que ajude a bajar las métricas del modelo y pueda ser un mejor modelo sin overfiting
param_grid = {
    'max_depth': [100, 150, 250], # Se ajusta la profundidad máxima del árbol
    'min_samples_split': [75, 150, 225], # Se ajusta mínimo número de muestras por hoja
    'min_samples_leaf': [10, 50, 150], # Se ajusta el mínimo número de muestras para dividir un nodo
    'criterion': ['gini', 'entropy'] # Se ajusta la manera en la que aprende el árbol
}

# Ahora se hace el GridSearch para saber cuales son los mejores Hiper parámetros del conjunto anterior
grid_search = GridSearchCV(model_tree, param_grid, cv=3, scoring='accuracy')
# Se entrena el modelo con los nuevos hiper parámetros
grid_search.fit(X_train_encoded, y_train)

# Se asigan los mejores hiper parámetros
best_params = grid_search.best_params_

# Se enseñan los mejores hiper parámetros
print('Mejores parámetros:', best_params)

# Se hacen las predicciones con el nuevo árbol de desiciones
y_pred_2 = grid_search.predict(X_test_encoded)

# Se calculan las métricas con los nuevos resultados del Árbol y de esta manera evitar el sobreentrenamiento
accuracy2 = accuracy_score(y_test, y_pred_2)
precision2 = precision_score(y_test, y_pred_2, average='weighted')
f1_2 = f1_score(y_test, y_pred_2, average='weighted')
recall2 = recall_score(y_test, y_pred_2, average='weighted')

# Puntaje del Arbol de desiciones después de las pruebas (Hiper parametros ajustados)
print("Árbol de desiciones con Hiper prarámetros ajustados")
print('Score de accuracy:', round(accuracy2, 4))
print('Score de precisión:', round(precision2, 4))
print('Score f1:', round(f1_2, 4))
print('Score de recall:', round(recall2, 4))

# Gráfica de accuracy de los dos modelos
precisiones = [accuracy, accuracy2] # Se pone el resultado de la métrica de accuracy de los 2 modelos
labels = ['Modelo 1 (Sin hiperparámetros)', 'Modelo 2 (Hiperparámetros Ajustados)'] # Se asigan nombres a cada barra de la gráfica

# Crear gráfico de barras
plt.figure(figsize=(8, 4))
plt.bar(labels, precisiones, color=['blue', 'green'])

# Crear las etiquetas
plt.ylabel('Accuracy (%)')
plt.title('Comparación de Accuracy entre Modelos')
plt.ylim(0, 1)

# Mostrar la gráfica
plt.show()

# Gráfica de Presicion de los dos modelos
precisiones = [precision, precision2] # Se pone el resultado de la métrica de Presicion de los 2 modelos
labels = ['Modelo 1 (Sin hiperparámetros)', 'Modelo 2 (Hiperparámetros Ajustados)'] # Se asigan nombres a cada barra de la gráfica

# Crear gráfico de barras
plt.figure(figsize=(8, 4))
plt.bar(labels, precisiones, color=['blue', 'green'])

# Crear las etiquetas
plt.ylabel('Precisión (%)')
plt.title('Comparación de Presicion entre Modelos')
plt.ylim(0, 1)

# Mostrar la gráfica
plt.show()

# Gráfica de F1_Score de los dos modelos
precisiones = [f1, f1_2] # Se pone el resultado de la métrica de F1_Score de los 2 modelos
labels = ['Modelo 1 (Sin hiperparámetros)', 'Modelo 2 (Hiperparámetros Ajustados)'] # Se asigan nombres a cada barra de la gráfica

# Crear gráfico de barras
plt.figure(figsize=(8, 4))
plt.bar(labels, precisiones, color=['blue', 'green'])

# Crear las etiquetas
plt.ylabel('F1 (%)')
plt.title('Comparación de F1 entre Modelos')
plt.ylim(0, 1)

# Mostrar la gráfica
plt.show()

# Gráfica de Recall_Score de los dos modelos
precisiones = [recall, recall2] # Se pone el resultado de la métrica de Recall_Score de los 2 modelos
labels = ['Modelo 1 (Sin hiperparámetros)', 'Modelo 2 (Hiperparámetros Ajustados)'] # Se asigan nombres a cada barra de la gráfica

# Crear gráfico de barras
plt.figure(figsize=(8, 4))
plt.bar(labels, precisiones, color=['blue', 'green'])

# Crear las etiquetas
plt.ylabel('Recall (%)')
plt.title('Comparación de Recall entre Modelos')
plt.ylim(0, 1)

# Mostrar la gráfica
plt.show()